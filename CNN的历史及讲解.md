http://lib.csdn.net/article/computervison/50556

过去几年，深度学习在解决诸如视觉识别、语音识别和自然语言处理等很多问题方面都表现出色。在不同类型的神经网络当中，卷积神经网络是得到最深入研究的。早期由于缺乏训练数据和计算能力，要在不产生过拟合的情况下训练高性能卷积神经网络是很困难的。标记数据和近来GPU的发展，使得卷积神经网络研究涌现并取得一流结果。

## 1 Lenet-5

### 20世纪 90 年代，LeCun et al. [3] 等人发表论文，确立了CNN的现代结构，后来又对其进行完善。他们设计了一种多层的人工神经网络，取名叫做LeNet-5，可以对手写数字做分类。和其他神经网络一样， LeNet-5 也能使用 backpropagation 算法训练。 

### LeNet5 的架构基于这样的观点：（尤其是）图像的特征分布在整张图像上，以及带有可学习参数的卷积是一种用少量参数在多个位置上提取相似特征的有效方式。LeNet5特征能够总结为如下几点：1）卷积神经网络使用三个层作为一个系列： 卷积，池化，非线性 2） 使用卷积提取空间特征 3）使用映射到空间均值下采样（subsample） 4）双曲线（tanh）或S型（sigmoid）形式的非线性 5）多层神经网络（MLP）作为最后的分类器 6）层与层之间的稀疏连接矩阵避免大的计算成本　





2006年起，人们设计了很多方法，想要克服难以训练深度CNN的困难。其中，最著名的是 Krizhevsky et al.提出了一个经典的CNN 结构，并在图像识别任务上取得了重大突破。其方法的整体框架叫做 AlexNet。

AlexNet 取得成功后，研究人员又提出了其他的完善方法，其中最著名的要数 ZFNet [7], VGGNet [8], GoogleNet [9] 和 ResNet [10] 这四种。从结构看，CNN 发展的一个方向就是层数变得更多，ILSVRC 2015 冠军 ResNet 是 AlexNet 的20 多倍，是 VGGNet 的8 倍多。






