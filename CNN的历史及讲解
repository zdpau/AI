http://lib.csdn.net/article/computervison/50556

过去几年，深度学习在解决诸如视觉识别、语音识别和自然语言处理等很多问题方面都表现出色。在不同类型的神经网络当中，卷积神经网络是得到最深入研究的。早期由于缺乏训练数据和计算能力，要在不产生过拟合的情况下训练高性能卷积神经网络是很困难的。标记数据和近来GPU的发展，使得卷积神经网络研究涌现并取得一流结果。

20世纪 90 年代，LeCun et al. [3] 等人发表论文，确立了CNN的现代结构，后来又对其进行完善。他们设计了一种多层的人工神经网络，取名叫做LeNet-5，可以对手写数字做分类。和其他神经网络一样， LeNet-5 也能使用 backpropagation 算法训练。 　　

2006年起，人们设计了很多方法，想要克服难以训练深度CNN的困难。其中，最著名的是 Krizhevsky et al.提出了一个经典的CNN 结构，并在图像识别任务上取得了重大突破。其方法的整体框架叫做 AlexNet。

AlexNet 取得成功后，研究人员又提出了其他的完善方法，其中最著名的要数 ZFNet [7], VGGNet [8], GoogleNet [9] 和 ResNet [10] 这四种。从结构看，CNN 发展的一个方向就是层数变得更多，ILSVRC 2015 冠军 ResNet 是 AlexNet 的20 多倍，是 VGGNet 的8 倍多。






