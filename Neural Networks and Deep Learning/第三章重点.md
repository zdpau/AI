当一个高尔夫球员刚开始学习打高尔夫时，他们通常会在挥杆的练习上花费大多数时间。慢慢地他们才会在基本的挥杆上通过变化发展其他的击球方式，学习低飞球、左曲球和右曲球。类似的，我们现在仍然聚焦在反向传播算法的理解上。这就是我们的“基本挥杆”——神经网络中大部分工作学习和研究的基础。本章，我会解释若干技术能够用来提升我们关于反向传播的初级的实现，最终改进网络学习的方式。

本章涉及的技术包括：更好的代价函数的选择——交叉熵 代价函数；四中规范化方法（L1 和 L2 规范化，dropout 和训练数据的人工扩展），这会让我们的网络在训练集之外的数据上更好地泛化；更好的权重初始化方法；还有帮助选择好的超参数的启发式想法。

## 交叉熵代价函数
将交叉熵看做是代价函数有两点原因。第一，它使非负的，C>0。可以看出：(a) 公式(57)的和式中所有独立的项都是非负的，因为对数函数的定义域是 (0,1)；(b) 前面有一个负号。

第二，如果神经元实际的输出接近目标值。假设在这个例子中，y=0 而 a≈0。这是我们想到得到的结果。我们看到公式(57)中第一个项就消去了，因为 y=0，而第二项实际上就是 −ln(1−a)≈0。反之，y=1 而 a≈1。所以在实际输出和目标输出之间的差距越小，最终的交叉熵的值就越低了。

综上所述，交叉熵是非负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是二次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有一个比二次代价函数更好的特性就是它避免了学习速度下降的问题。

它告诉我们权重学习的速度受到 σ(z)−y，也就是输出中的误差的控制。更大的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在二次代价函数中类似公式中 σ′(z) 导致的学习缓慢，见公式(55)。当我们使用交叉熵的时候，σ′(z) 被约掉了，所以我们不再需要关心它是不是变得很小。这种约除就是交叉熵带来的特效。

如果你观测的足够仔细，你可以发现代价函数曲线要比二次代价函数训练前面部分要陡很多。正是交叉熵带来的快速下降的坡度让神经元在处于误差很大的情况下能够逃脱出学习缓慢的困境，这才是我们直觉上所期待的效果。

**那么我们应该在什么时候用交叉熵来替换二次代价函数？**实际上，如果在输出神经元使用 sigmoid 激活函数时，交叉熵一般都是更好的选择。为什么？考虑一下我们初始化网络的时候通常使用某种随机方法。可能会发生这样的情况，这些初始选择会对某些训练输入误差相当明显——比如说，目标输出是 1，而实际值是 0，或者完全反过来。如果我们使用二次代价函数，那么这就会导致学习速度的下降。它并不会完全终止学习的过程，因为这些权重会持续从其他的样本中进行学习，但是显然这不是我们想要的效果。

## 理解神经元饱和和如何解决这个问题

**问题**：已经深入讨论了使用二次代价函数的网络中在输出神经元饱和时候学习缓慢的问题，另一个可能会影响学习的因素就是在方程(61)中的 xj 项。由于此项，当输入 xj 接近 0 时，对应的权重 xj 会学习得相当缓慢。解释为何不可以通过改变代价函数来消除 xj 项的影响。

## 交叉熵的含义？源自哪里？
我们对于交叉熵的讨论聚焦在代数分析和代码实现。这虽然很有用，但是也留下了一个未能回答的更加宽泛的概念上的问题，如：交叉熵究竟表示什么？存在一些直觉上的思考交叉熵的方法么？我们如何想到这个概念？

让我们从最后一个问题开始回答：什么能够激发我们想到交叉熵？假设我们发现学习速度下降了，并理解其原因是因为在公式(55)(56)中的 σ′(z) 那一项。在研究了这些公式后，我们可能就会想到选择一个不包含 σ′(z) 的代价函数。

## Softmax
softmax 的想法其实就是为神经网络定义一种新式的输出层。softmax 层的输出是一些相加为 1 正数的集合。换言之，softmax 层的输出可以被看做是一个概率分布。暴力的话，直接将最大的数设为1。在神经网络中，描述多类分类问题时，输出层会设置多个节点，常用 softmax 作为输出层的激活函数，称为softmax层.

softmax的指数函数确保了所有的输出激活值是正数。然后分母的求和又保证了 softmax 的输出和为 1。所以这个特定的形式不再像之前那样难以理解了：反而是一种确保输出激活值形成一个概率分布的自然的方式。你可以将其想象成一种重新调节 zLj 的方法，然后将这个结果整合起来构成一个概率分布。

https://baike.baidu.com/item/Softmax%E5%87%BD%E6%95%B0/22772270?fr=aladdin (最底下有sigmoid和softmax的对比)

这样的效果很令人满意。在很多问题中，将这些激活值作为网络对于某个输出正确的概率的估计非常方便。所以，比如在 MNIST 分类问题中，我们可以将 aLj 解释成网络估计正确数字分类为 j 的概率。

对比一下，如果输出层是 sigmoid 层，那么我们肯定不能假设激活值形成了一个概率分布。我不会证明这一点，但是源自 sigmoid 层的激活值是不能够形成一种概率分布的一般形式的。所以使用 sigmoid 输出层，我们没有关于输出的激活值的简单的解释。

## 学习缓慢问题：我们现在已经对 softmax 神经元有了一定的认识。但是我们还没有看到 softmax 会怎么样解决学习缓慢问题。

为了理解这点，先定义一个 log-likelihood 代价函数。我们使用 x 表示训练输入，y 表示对应的目标输出。然后关联这个训练输入样本的 log-likelihood 代价函数就是： C≡−lnaLy.

如果我们训练的是 MNIST 图像，输入为 7 的图像，那么对应的 log-likelihood 代价就是 −lnaL7。看看这个直觉上的含义，想想当网络表现很好的时候，也就是确认输入为 7 的时候。这时，他会估计一个对应的概率 aL7 跟 1 非常接近，所以代价 −lnaL7 就会很小。反之，如果网络的表现糟糕时，概率 aL7 就变得很小，代价 −lnaL7 随之增大。所以 log-likelihood 代价函数也是满足我们期待的代价函数的条件的。

关于学习缓慢问题呢？为了分析它，回想一下学习缓慢的关键就是量 ∂C/∂wLjk 和 ∂C/∂bLj 的变化情况。softmax的情况是：

![avatar](https://upload-images.jianshu.io/upload_images/42741-2ca3c9d2f0c4d8a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

将 softmax 输出层和 log-likelihood 组合  对照   sigmoid 输出层和交叉熵的组合类比着看是非常有用的。

有了这样的相似性，你会使用哪一种呢？实际上，在很多应用场景中，这两种方式的效果都不错。作为一种更加通用的视角，**softmax 加上 log-likelihood 的组合更加适用于那些需要将输出激活值解释为概率的场景。当然这不总是合理的，但是在诸如 MNIST 这种有着不重叠的分类问题上确实很有用。**

## 过拟合和规范化
检测过匹配的明显方法是使用上面的方法——跟踪测试数据集合上的准确度随训练变化情况。

我们会使用 validation_data 来防止过匹配。我们会使用和上面应用在 test_data 的策略。我们每个回合都计算在 validation_data 上的分类准确度。一旦分类准确度已经饱和，就停止训练。这个策略被称为 提前停止（Early stopping）。当然，实际应用中，我们不会立即知道什么时候准确度会饱和。相反，我们会一直训练知道我们确信准确度已经饱和。

为何要使用 validation_data 来替代 test_data 防止过匹配问题？实际上，这是一个更为一般的策略的一部分，这个一般的策略就是使用 validation_data 来衡量不同的超参数（如训练回合，学习率，最好的网络架构等等）的选择的效果。我们使用这样方法来找到超参数的合适值。

为何用validation_data 取代 test_data 来设置更好的超参数？为了理解这点，想想当设置超参数时，我们想要尝试许多不同的超参数选择。如果我们设置超参数是基于 test_data 的话，可能最终我们就会得到过匹配于 test_data 的超参数。也就是说，我们可能会找到那些 符合 test_data 特点的超参数，但是网络的性能并不能够泛化到其他数据集合上。我们借助 validation_data 来克服这个问题。然后一旦获得了想要的超参数，最终我们就使用 test_data 进行准确度测量。这给了我们在 test_data 上结果是一个网络泛化能力真正的度量方式的信心。换言之，**你可以将验证集看成是一种特殊的训练数据集能够帮助我们学习好的超参数。这种寻找好的超参数的观点有时候被称为 hold out 方法，因为 validation_data 是从训练集中保留出来的一部分。**

最好的降低过匹配的方式之一就是增加训练样本的量。有了足够的训练数据，就算是一个规模非常大的网络也不大容易过匹配。不幸的是，训练数据其实是很难或者很昂贵的资源，所以这不是一种太切实际的选择。

## 规范化:正则化的目的是限制参数过多或者过大，避免模型更加复杂。
增加训练样本的数量是一种减轻过匹配的方法。还有其他的一下方法能够减轻过匹配的程度么？一种可行的方式就是降低网络的规模。然而，大的网络拥有一种比小网络更强的潜力，所以这里存在一种应用冗余性的选项。

幸运的是，**还有其他的技术能够缓解过匹配，即使我们只有一个固定的网络和固定的训练集合**。这种技术就是**规范化**。本节，我会给出一种最为常用的规范化手段——有时候被称为权重下降（weight decay）或者 L2 规范化。L2 规范化的想法是增加一个额外的项到代价函数上，这个项叫做 规范化 项。下面是规范化交叉熵：

**L2范数也被称为权重衰减（weight decay），为什么称为权重衰减，这个我们一会就会知道。线性回归中应用L2范数也被称为岭回归，在其他文献中也有将L2范数称为Tikhonov正则。L2参数正则化就是在损失函数中加入一个L2范数和一个超参数lambda，L2范数用||w||^2这种符号表示，它的意思是对于向量w中的各个数先求平方再加和。线性回归中加入的对于theta j求平方和就是一个L2范数。而超参数lambda则用于控制参数惩罚的程度。**

![avatar](https://upload-images.jianshu.io/upload_images/42741-c568fcb86507d225.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中第一个项就是常规的交叉熵的表达式。第二个现在加入到就是所有权重的平方的和。然后使用一个因子 λ/2n 进行量化调整，其中 λ>0 可以成为 规范化参数，而 n 就是训练集合的大小。我们会在后面讨论 λ 的选择策略。需要注意的是，规范化项里面并不包含偏差。

当然，对其他的代价函数也可以进行规范化，例如二次代价函数。类似的规范化的形式如下：

![avatar](https://upload-images.jianshu.io/upload_images/42741-5ac129550876960e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

直觉地看，规范化的效果是让网络倾向于学习小一点的权重，其他的东西都一样的。大的权重只有能够给出代价函数第一项足够的提升时才被允许。换言之，规范化可以当做一种寻找小的权重和最小化原始的代价函数之间的折中。这两部分之前相对的重要性就由 λ 的值来控制了：λ 越小，就偏向于最小化原始代价函数，反之，倾向于小的权重。

将随机梯度下降算法应用在一个规范化的神经网络上。特别地，我们需要知道如何计算偏导数 ∂C/∂w 和 ∂C/∂b。对公式(87)进行求偏导数得：

![avatar](https://upload-images.jianshu.io/upload_images/42741-5245cdeb7e21cfa6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

∂C0/∂w 和 ∂C0/∂b 可以通过反向传播进行计算，和上一章中的那样。所以我们看到其实计算规范化的代价函数的梯度是很简单的：仅仅需要反向传播，然后加上 λnw 得到所有权重的偏导数。而偏差的偏导数就不要变化，所以梯度下降学习规则不会发生变化：

![avatar](https://upload-images.jianshu.io/upload_images/42741-e799b9aa2f4bfde1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

权重的学习规则就变成：

![avatar](https://upload-images.jianshu.io/upload_images/42741-d67877a26e275e8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

除了乘了 1−ηλn 因子。这里就是权重下降的来源。粗看，这样会导致权重会不断下降到 0。但是实际不是这样的，因为如果在原始代价函数中造成下降的话其他的项可能会让权重增加。

好的，这就是梯度下降工作的原理。那么随机梯度下降呢？正如在没有规范化的随机梯度下降中，我们可以通过平均 minibatch 中 m 个训练样本来估计 ∂C0/∂w。因此，为了随机梯度下降的规范化学习规则就变成：

![avatar](https://upload-images.jianshu.io/upload_images/42741-8250a8cd3dbd1d84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中后面一项是对 minibatch 中的训练样本 x 进行求和，而 Cx 是对每个训练样本的（无规范化的）代价。这其实和之前通常的随机梯度下降的规则是一样的，除了有一个权重下降的因子 1−ηλn。最后，为了完备性，我给出偏差的规范化的学习规则。这当然是和我们之前的非规范化的情形一致了

![avatar](https://upload-images.jianshu.io/upload_images/42741-52af952c5409f9e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们讨论了作为一种减轻过匹配和提高分类准确度的方式的规范化技术。实际上，这不是仅有的好处。实践表明，在使用不同的（随机）权重初始化进行多次 MNIST 网络训练的时候，我发现**无规范化的网络会偶然被限制住，明显困在了代价函数的局部最优值处。结果就是不同的运行会给出相差很大的结果。对比看来，规范化的网络能够提供更容易复制的结果。**

为何会这样子？从经验上看，如果代价函数是无规范化的，那么权重向量的长度可能会增长，而其他的东西都保持一样。随着时间的推移，这个会导致权重向量变得非常大。所以会使得权重向困在差不多方向上，因为由于梯度下降的改变当长度很大的时候仅仅会在那个方向发生微小的变化。我相信这个现象让学习算法更难有效地探索权重空间，最终导致很难找到代价函数的最优值。

## 为何规范化可以帮助减轻过匹配
通常的说法是：小的权重在某种程度上，意味着更低的复杂性，也就给出了一种更简单却更强大的数据解释，因此应该优先选择。

假设神经网络大多数有很小的权重，这最可能出现在规范化的网络中。更小的权重意味着网络的行为不会因为我们随便改变了一个输入而改变太大。这会让规范化网络学习局部噪声的影响更加困难。将它看做是一种让单个的证据不会影响网络输出太多的方式。相对的，规范化网络学习去对整个训练集中经常出现的证据进行反应。对比看，大权重的网络可能会因为输入的微小改变而产生比较大的行为改变。所以一个无规范化的网络可以使用大的权重来学习包含训练数据中的噪声的大量信息的复杂模型。**简言之，规范化网络受限于根据训练数据中常见的模式来构造相对简单的模型，而能够抵抗训练数据中的噪声的特性影响。我们的想法就是这可以让我们的网络对看到的现象进行真实的学习，并能够根据已经学到的知识更好地进行泛化。**

所以，倾向于更简单的解释的想法其实会让我们觉得紧张。人们有时候将这个想法称为**“奥卡姆剃刀原则”**，然后就会热情地将其当成某种科学原理来应用这个法则。但是，这就不是一个一般的科学原理。也没有任何先验的逻辑原因来说明简单的解释就比更为负责的解释要好。实际上，有时候更加复杂的解释其实是正确的。

到现在还没有一个人能够发展出一整套具有说服力的关于规范化可以帮助网络泛化的理论解释。

**L2 规范化没有限制偏差**。当然了，对规范化的过程稍作调整就可以对偏差进行规范了。实践看来，做出这样的调整并不会对结果改变太多，所以，在某种程度上，对不对偏差进行规范化其实就是一种习惯了。然而，需要注意的是，有一个大的偏差并不会像大的权重那样会让神经元对输入太过敏感。所以我们不需要对大的偏差所带来的学习训练数据的噪声太过担心。同时，允许大的偏差能够让网络更加灵活——因为，大的偏差让神经元更加容易饱和，这有时候是我们所要达到的效果。**所以，我们通常不会对偏差进行规范化**。

## 规范化的其他技术
三种减轻过匹配的其他的方法：L1 规范化、dropout 和人工增加训练样本。

**L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0，换句话说，就是让参数W是稀疏的。通常使参数稀疏都是用L1范数实现，L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。**


### L1 规范化：这个方法其实是在代价函数上加上一个权重绝对值的和：

![avatar](https://upload-images.jianshu.io/upload_images/42741-4965f6123f128153.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

直觉上看，这和 L2 规范化相似，惩罚大的权重，倾向于让网络的权重变小。当然，L1 规范化和 L2 规范化并不相同，所以我们不应该期望 L1 规范化是进行同样的行为。让我们来看看试着理解使用 L1 规范化和 L2 规范化所不同的地方。首先，我们会研究一下代价函数的偏导数。对(95)求导我们有：

![avatar](https://upload-images.jianshu.io/upload_images/42741-b4f1bc0df09ede97.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中 sgn(w) 就是 w 的正负号。使用这个表达式，我们可以轻易地对反向传播进行修改从而使用基于 L1 规范化的随机梯度下降进行学习。对 L1 规范化的网络进行更新的规则就是：

![avatar](https://upload-images.jianshu.io/upload_images/42741-af9d539b92b9e219.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中和往常一样，我们可以用 minibatch 的均值来估计 ∂C0/∂w。对比公式(93)的 L2 规范化，

![avatar](https://upload-images.jianshu.io/upload_images/42741-2f6516012f4a5439.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**在两种情形下，规范化的效果就是缩小权重。**这和我们想要让权重不会太大的直觉目标相符。**在 L1 规范化中，权重按照一个接近 0 的常量进行缩小。在 L2 规范化中，权重同按照一个和 w 成比例的量进行缩小的。所以，当一个特定的权重绝对值 |w|很大时，L1 规范化缩小得远比 L2 规范化要小得多。而一个特定的权重绝对值 |w|很小时，L1 规范化权值要比 L2 规范化缩小得更大。最终的结果就是：L1 规范化倾向于聚集网络的权重在相对少量的高重要度连接上，而其他权重就会被驱使向 0 接近。**

我在上面的讨论中其实忽略了一个问题——在 w=0 的时候，偏导数 ∂C/∂w 未定义。原因在于函数 |w| 在 w=0 时有个直角，事实上，导数是不存在的。不过也没有关系。我们下面要做的就是应用无规范化的通常的梯度下降的规则在 w=0 处。这应该不会有什么问题，直觉上看，规范化的效果就是缩小权重，显然，不能对一个已经是 0 的权重进行缩小了。更准确地说，我们将会使用方程(96)(97)并约定 sgn(0)=0。这样就给出了一种紧致的规则来进行采用 L1 规范化的随机梯度下降学习。

**总结一下L1与L2范数：**

>* L1范数：L1范数在正则化的过程中会趋向于产生少量的特征，而其他的特征都是0（L1会使得参数矩阵变得稀疏）。因此L1不仅可以起到正则化的作用，还可以起到特征选择的作用。

>* L2范数：L2范数是通过使权重衰减，进而使得特征对于总体的影响减小而起到防止过拟合的作用的。L2的优点在于求解稳定、快速。

**提到了稀疏，也知道了L1范数可以实现稀疏，那么稀疏有什么好处呢？**
* 1.特征选择，稀疏的矩阵可以起到特征选择的作用。我们知道，稀疏矩阵是只有少数值为非零，大多数值为0的矩阵。有些场景中特征数量可能会非常多，不利于直接使用机器学习算法。如果这是可以将参数矩阵转换稀疏的，那么就可以只保留一小部分特征（只有系数为非零的那一部分特征被保留）。这样转换成稀疏矩阵就可以起到特征选择的作用。

* 2.可解释性。另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1*x1+w2*x2+…+w1000*x1000+b（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w*就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。

* 3.减少内存消耗。有些人认为稀疏矩阵可以减少内存消耗，因为这样存的元素会少一些。对于这一点，我不太确定。


![avatar]()

![avatar]()

![avatar]()

![avatar]()
