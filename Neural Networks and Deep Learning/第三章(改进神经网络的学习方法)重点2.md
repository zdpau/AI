http://neuralnetworksanddeeplearning.com/chap3.html

https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/chapter3b.html

## 权重初始化
之前的方式就是根据独立的均值为 0，标准差为 1 的高斯随机变量随机采样作为权重和偏差的初始值。这个方法工作的还不错，但是非常 ad hoc。但这其实是可行的，因为这样并不会让我们的神经网络更容易饱和。实际上，其实已经避免了饱和的问题的话，如何初始化偏差影响不大。

假设我们有一个有 nin 个输入权重的神经元。我们会使用均值为 0 标准差为 1/√nin 的高斯分布初始化这些权重。也就是说，我们会向下挤压高斯分布，让我们的神经元更不可能饱和，我们会继续使用均值为 0 标准差为 1 的高斯分布来对偏差进行初始化（使用了均值为 0 而标准差为 1/√n，n为对应的输入连接个数。我们使用均值为 0 而标准差为 1 的高斯分布来初始化偏差。） （回去看原文，没理解）

## 如何选择神经网络的超参数
本节，我会给出一些用于设定超参数的启发式想法。目的是帮你发展出一套工作流来确保很好地设置超参数。当然，我不会覆盖超参数优化的每个方法。那是太繁重的问题，而且也不会是一个能够完全解决的问题，也不存在一种通用的关于正确策略的共同认知。总是会有一些新的技巧可以帮助你提高一点性能。但是本节的启发式想法能帮你开个好头。

宽泛的策略：
>* 可以将问题简化。丢开训练和验证集合中的那些除了 0 和 1 的那些图像。然后试着训练一个网络来区分 0 和 1。不仅仅问题比 10 个分类的情况简化了，同样也会减少 80% 的训练数据，这样就给出了 5 倍的加速。这样可以保证更快的实验，也能给予你关于如何构建好的网络更快的洞察。

>* 通过简化网络来加速实验进行更有意义的学习。如果你相信 [784,10] 的网络更可能比随机更加好的分类效果，那么就从这个网络开始实验。这会比训练一个 [784,30,10] 的网络更快.

>* 通过提高监控的频率来在试验中获得另一个加速了。

所有这些作为一种宽泛的策略看起来很有前途。然而，回到寻找超参数的原点。实际上,上面的讨论也传达出过于乐观的观点。实际上，很容易会遇到神经网络学习不到任何知识的情况。你可能要花费若干天在调整参数上，仍然没有进展。所以我想要再重申一下在前期你应该从实验中尽可能早的获得快速反馈。直觉上看，这看起来简化问题和架构仅仅会降低你的效率。实际上，这样能够将进度加快，因为你能够更快地找到传达出有意义的信号的网络。一旦你获得这些信号，你可以尝尝通过微调超参数获得快速的性能提升。这和人生中很多情况一样——万事开头难。

具体的策略：聚焦在学习率 η，L2 规范化参数 λ，和 minibatch 大小。

![avatar](https://upload-images.jianshu.io/upload_images/42741-bd87b721fb6d54bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

1，设置 η。首先，我们选择在训练数据上的代价立即开始下降而非震荡或者增加时作为 η 的阈值的估计。这个估计并不需要太过精确。你可以估计这个值的量级，比如说从 η=0.01 开始。如果代价在训练的前面若干回合开始下降(学习率太小，像上图0.025那样)，你就可以逐步地尝试 η=0.1,1.0,...，直到你找到一个 η 的值使得在开始若干回合代价就开始震荡或者增加。相反，如果代价在 η=0.01 时就开始震荡或者增加（学习率太大），那就尝试 η=0.001,0.0001,... 直到你找到代价在开始回合就下降的设定。按照这样的方法，我们可以掌握学习率的阈值的量级的估计。你可以选择性地优化估计，选择那些最大的 η，比方说 η=0.5 或者 η=0.2（这里也不需要过于精确）。   显然，η 实际值不应该比阈值大。实际上，如果 η 的值重复使用很多回合的话，你更应该使用稍微小一点的值，例如，阈值的一半这样的选择。这样的选择能够允许你训练更多的回合，不会减慢学习的速度。

>* 然而，使用训练代价函数来选择 η 看起来和我们之前提到的通过验证集来确定超参数的观点有点矛盾。实际上，我们会使用验证准确度来选择规范化超参数，minibatch 大小，和层数及隐藏元个数这些网络参数，等等。为何对学习率要用不同的方法呢？坦白地说，这些选择其实是我个人美学偏好，个人习惯罢了。原因就是其他的超参数倾向于提升最终的测试集上的分类准确度，所以将他们通过验证准确度来选择更合理一些。然而，学习率仅仅是偶然地影响最终的分类准确度的。学习率主要的目的是控制梯度下降的步长，监控训练代价是最好的检测步长过大的方法。所以，这其实就是个人的偏好。在学习的前期，如果验证准确度提升，训练代价通常都在下降。所以在实践中使用那种衡量方式并不会对判断的影响太大。

2，使用 Early stopping 来确定训练的回合数：表示在每个回合的最后，我们都要计算验证集上的分类准确度。当准确度不再提升，就终止它。

一种不错的解决方案是如果分类准确度在一段时间内不再提升的时候终止。例如，我们要解决 MNIST 问题。如果分类准确度在近 10 个回合都没有提升的时候，我们将其终止。

>* 然而，网络有时候会在很长时间内于一个特定的分类准确度附近形成平缓的局面，然后才会有提升。如果你尝试获得相当好的性能，这个规则可能就会太过激进了——停止得太草率。所以，我建议在你更加深入地理解网络训练的方式时，仅仅在初始阶段使用 10 回合不提升规则，然后逐步地选择更久的回合，比如说：20 回合不提升就终止，20 回合不提升就终止，以此类推。当然，这就引入了一种新的需要优化的超参数！

3，如何设置学习率呢？其实有很多方法。一种自然的观点是使用提前终止的想法。就是保持学习率为一个常量知道验证准确度开始变差。然后按照某个量下降学习率，比如说按照 10 或者 2。我们重复此过程若干次，知道学习率是初始值的 1/1024（或者1/1000）。那时就终止。

>* 可变学习率可以提升性能，但是也会产生大量可能的选择。这些选择会让人头疼——你可能需要花费很多精力才能优化学习规则。对刚开始实验，我建议使用单一的常量作为学习率的选择。这会给你一个比较好的近似。

4, 规范化参数：建议，开始时不包含规范化（λ=0.0），确定 η 的值。使用确定出来的 η，我们可以使用验证数据来选择好的 λ。从尝试 λ=1.0 开始，然后根据验证集上的性能按照因子 10增加或减少其值。一旦我已经找到一个好的量级，你可以改进 λ 的值。这里搞定后，你就可以返回再重新优化 η。

5, minibatch 大小：我们应该如何设置 minibatch 的大小？为了回答这个问题，让我们先假设正在进行在线学习，也就是说使用大小为 1 的minibatch。

对在线学习的明显担心是，使用仅包含一个训练示例的小批量将导致我们对梯度的估计出现重大错误。事实上，错误结果并非如此。原因是个别梯度估计不需要超精确。 我们所需要的只是一个足够准确的估计--我们的成本函数往往会不断下降。

所以，选择最好的 minibatch 大小也是一种折衷。太小了，你不会用上很好的矩阵库的快速计算。太大，你是不能够足够频繁地更新权重的。

幸运的是，minibatch 大小的选择其实是相对独立的一个超参数（网络整体架构外的参数），所以你不需要优化那些参数来寻找好的 minibatch 大小。因此，可以选择的方式就是使用某些可以接受的值（不需要是最优的）作为其他参数的选择，然后进行不同 minibatch 大小的尝试，像上面那样调整 η。画出验证准确度的值随时间（非回合）变化的图，选择哪个得到最快性能的提升的 minibatch 大小。得到了 minibatch 大小，也就可以对其他的超参数进行优化了。

6,自动技术：说了很多手动进行超参数优化时的启发式规则。手动选择当然是种理解网络行为的方法。不过，现实是，很多工作已经使用自动化过程进行。通常的技术就是**网格搜索（grid search）**，可以系统化地对超参数的参数空间的网格进行搜索。

### 总结：实践中，超参数之间存在着很多关系。你可能使用 η 进行试验，发现效果不错，然后去优化 λ，发现这里又对 η 混在一起了。在实践中，一般是来回往复进行的，最终逐步地选择到好的值。总之，启发式规则其实都是经验，不是金规玉律。你应该注意那些没有效果的尝试的信号，然后乐于尝试更多试验。特别地，这意味着需要更加细致地监控神经网络行为，特别是验证集上的准确度。

如何选择超参数的方法太繁多，Yoshua Bengio 在 2012 年的论文中给出了一些实践上关于训练神经网络用到的反向传播和梯度下降的技术的推荐策略。Bengio 对很多问题的讨论比我这里更加细致，其中还包含如何进行系统化的超参数搜索。另一篇文章是 1998 年的 Yann LeCun、Léon Bottou、Genevieve Orr 和 Klaus-Robert Müller 的。

## 随机梯度下降的变种
通过反向传播进行的随机梯度下降已经在 MNIST 数字分类问题上有了很好的表现。然而，还有很多其他的观点来优化代价函数，有时候，这些方法能够带来比 minibatch 随机梯度下降更好的效果。本节，我会介绍两种观点，Hessian 和 momentum 技术。（想看看原文）

这个最小化代价函数的方法常常被称为 Hessian 技术 或者 Hessian 优化。在理论上和实践中的结果都表明 Hessian 方法比标准的梯度下降方法收敛速度更快。特别地，通过引入代价函数的二阶变化信息，可以让 Hessian 方法避免在梯度下降中常碰到的多路径（pathologies）问题。而且，反向传播算法的有些版本也可以用于计算 Hessian。

如果 Hessian 优化这么厉害，为何我们这里不使用它呢？不幸的是，尽管 Hessian 优化有很多可取的特性，它其实还有一个不好的地方：在实践中很难应用。这个问题的部分原因在于 Hessian 矩阵的太大了。假设你有一个 10^7 个权重和偏差的网络。那么对应的 Hessian 矩阵会有 10^7×10^7=10^14 个元素。这真的是太大了！所以在实践中，计算 H^−1∇C 就极其困难。不过，这并不表示学习理解它没有用了。实际上，有很多受到 Hessian 优化启发的梯度下降的变种，能避免产生太大矩阵的问题。让我们看看其中一个称为基于 momentum 梯度下降的方法。

直觉上看，Hessian 优化的优点是它不仅仅考虑了梯度，而且还包含梯度如何变化的信息。基于 momentum 的梯度下降就基于这个直觉，但是避免了二阶导数的矩阵的出现。为了理解 momentum 技术，想想我们关于梯度下降的原始图片，其中我们研究了一个球滚向山谷的场景。那时候，我们发现梯度下降，除了这个名字外，就类似于球滚向山谷的底部。momentum 技术修改了梯度下降的两处使之类似于这个物理场景。首先，为我们想要优化的参数引入了一个称为速度（velocity）的概念。梯度的作用就是改变速度，而不是直接的改变位置，就如同物理学中的力改变速度，只会间接地影响位置。第二，momentum 方法引入了一种摩擦力的项，用来逐步地减少速度。

给出更加准确的数学描述。我们引入对每个权重 wj 设置相应的速度变量 v=v1,v2,...。注意，这里的权重也可以笼统地包含偏差。然后我们将梯度下降更新规则 w→w′=w−η∇C 改成

![avatar](https://upload-images.jianshu.io/upload_images/42741-d740fbb37289ba2f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在这些方程中，μ 是用来控制阻碍或者摩擦力的量的超参数。为了理解这个公式，可以考虑一下当 μ=1 的时候，对应于没有任何摩擦力。所以，此时你可以看到力 ∇C 改变了速度，v，速度随后再控制 w 变化率。直觉上看，我们通过重复地增加梯度项来构造速度。这表示，如果梯度在某些学习的过程中几乎在同样的方向，我们可以得到在那个方向上比较大的移动量。

如果我们直接按坡度下降，每一步速度都不断增大，所以我们会越来越快地达到谷底。这样就能够确保 momentum 技术比标准的梯度下降运行得更快。当然，这里也会有问题，一旦达到谷底，我们就会跨越过去。或者，如果梯度本该快速改变而没有改变，那么我们会发现自己在错误的方向上移动太多了。**这就是在(107)式中使用 μ 这个超参数的原因了。** 前面提到，μ 可以控制系统中的摩擦力大小；更加准确地说，你应该将 1−μ 看成是摩擦力的量。当 μ=1 时，没有摩擦，速度完全由梯度 ∇C 决定。相反，若是 μ=0，就存在很大的摩擦，速度无法叠加，公式(107)(108)就变成了通常的梯度下降，w→w′=w−η∇C。在实践中，使用 0 和 1 之间的 μ 值可以给我们避免过量而又能够叠加速度的好处。我们可以使用 hold out 验证数据集来选择合适的 μ 值，就像我们之前选择 η 和 λ 那样。

关于 momentum 技术的一个很好的特点是它基本上不需要改变太多梯度下降的代码就可以实现。我们可以继续使用反向传播来计算梯度，就和前面那样，使用随机选择的 minibatch 的方法。

新技术包含共轭梯度下降和 BFGS 方法（也可以看看 limited memory BFGS，L-BFGS）。另一种近期效果很不错技术是 Nesterov 的加速梯度技术，这个技术对 momentum 技术进行了改进。

### Relu的优点：回想起 sigmoid 神经元在饱和时停止学习的问题，也就是输出接近 0 或者 1 的时候。在这章我们也反复看到了问题就是 σ′ 降低了梯度，减缓了学习。tanh 神经元也有类似的问题。对比一下，提高 RLU 的带权输入并不会导致其饱和，所以就不存在前面那样的学习速度下降。另外，当带权输入是负数的时候，梯度就消失了，所以神经元就完全停止了学习。这就是很多有关理解 RLU 何时何故更优的问题中的两个。
